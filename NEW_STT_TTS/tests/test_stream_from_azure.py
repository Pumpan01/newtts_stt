# ‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤ Library ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö Azure Speech, ‡πÄ‡∏™‡∏µ‡∏¢‡∏á, ‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡πÅ‡∏ß‡∏î‡∏•‡πâ‡∏≠‡∏° ‡πÅ‡∏•‡∏∞‡∏≠‡∏∑‡πà‡∏ô ‡πÜ
import azure.cognitiveservices.speech as speechsdk
import sounddevice as sd
import numpy as np
import threading
import time
import os
from dotenv import load_dotenv
from pathlib import Path


# ---------- Load API KEY ----------
# ‡πÇ‡∏´‡∏•‡∏î API Key ‡πÅ‡∏•‡∏∞ Region ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå .env
env_path = Path(__file__).resolve().parent / ".env"
load_dotenv(dotenv_path=env_path)

AZURE_SPEECH_KEY = os.getenv("AZURE_SPEECH_KEY")
AZURE_REGION = os.getenv("AZURE_SPEECH_REGION")


# ---------- Config ----------
SAMPLE_RATE = 16000        # ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ñ‡∏µ‡πà‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á 16kHz
FRAME_DURATION = 30        # ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡πÅ‡∏ï‡πà‡∏•‡∏∞ frame 30ms
FRAME_SIZE = int(SAMPLE_RATE * FRAME_DURATION / 1000)  # ‡∏Ñ‡∏≥‡∏ô‡∏ß‡∏ì‡∏Ç‡∏ô‡∏≤‡∏î frame


# ---------- Signal ----------
stop_signal = threading.Event()       # Signal ‡∏™‡∏±‡πà‡∏á‡∏´‡∏¢‡∏∏‡∏î STT
cancel_signal = threading.Event()     # Signal ‡πÅ‡∏à‡πâ‡∏á‡∏ß‡πà‡∏≤‡∏°‡∏µ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏û‡∏π‡∏î‡πÅ‡∏ó‡∏£‡∏Å
start_vad_signal = threading.Event()  # Signal ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á (VAD)
intent_result = None                  # ‡πÄ‡∏Å‡πá‡∏ö intent ‡∏ú‡∏•‡∏•‡∏±‡∏û‡∏ò‡πå (interrupt ‡∏´‡∏£‡∏∑‡∏≠ question)


# ---------- Intent Check ----------
# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏ï‡∏£‡∏ß‡∏à‡∏™‡∏≠‡∏ö‡∏ß‡πà‡∏≤‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏Ñ‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
def check_intent(text):
    question_keywords = ["‡∏≠‡∏∞‡πÑ‡∏£", "‡∏ó‡∏≥‡πÑ‡∏°", "‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏´‡∏£‡πà", "‡∏¢‡∏±‡∏á‡πÑ‡∏á", "‡∏ó‡∏µ‡πà‡πÑ‡∏´‡∏ô", "‡πÉ‡∏Ñ‡∏£", "‡πÉ‡∏ä‡πà‡πÑ‡∏´‡∏°", "‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏õ‡∏•‡πà‡∏≤", "‡∏Å‡∏µ‡πà", "‡πÑ‡∏´‡∏°"]
    for word in question_keywords:
        if word in text:
            return "question"   # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡∏Ñ‡∏≥‡∏ó‡∏µ‡πà‡∏ö‡πà‡∏á‡∏ö‡∏≠‡∏Å‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°
    return "interrupt"          # ‡∏ñ‡πâ‡∏≤‡πÑ‡∏°‡πà‡∏°‡∏µ ‚Üí ‡∏ñ‡∏∑‡∏≠‡∏ß‡πà‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏Å‡∏≤‡∏£‡∏û‡∏π‡∏î‡πÅ‡∏ó‡∏£‡∏Å


# ---------- STT Detect (Continuous) ----------
# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÄ‡∏õ‡∏¥‡∏î‡πÑ‡∏°‡∏Ñ‡πå‡∏ü‡∏±‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÅ‡∏ö‡∏ö‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á
def detect_human_voice_by_stt_continuous():
    global intent_result

    speech_config = speechsdk.SpeechConfig(subscription=AZURE_SPEECH_KEY, region=AZURE_REGION)
    speech_config.speech_recognition_language = "th-TH"
    audio_config = speechsdk.audio.AudioConfig(use_default_microphone=True)

    speech_recognizer = speechsdk.SpeechRecognizer(
        speech_config=speech_config, audio_config=audio_config
    )

    # ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ü‡∏±‡∏á‡πÑ‡∏î‡πâ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°
    def recognized(evt):
        global intent_result
        if start_vad_signal.is_set():   # ‡∏ï‡∏£‡∏ß‡∏à‡πÄ‡∏â‡∏û‡∏≤‡∏∞‡∏ï‡∏≠‡∏ô‡πÄ‡∏õ‡∏¥‡∏î VAD
            text = evt.result.text.strip()
            if text:
                print(f"üõë ‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏û‡∏π‡∏î: {text}")
                intent_result = check_intent(text)  # ‡πÄ‡∏ä‡πá‡∏Ñ intent
                cancel_signal.set()                 # ‡πÅ‡∏à‡πâ‡∏á‡∏ß‡πà‡∏≤‡∏°‡∏µ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏û‡∏π‡∏î‡πÅ‡∏ó‡∏£‡∏Å

    def canceled(evt):
        print(f"‚ùå STT ‡∏¢‡∏Å‡πÄ‡∏•‡∏¥‡∏Å: {evt}")

    speech_recognizer.recognized.connect(recognized)
    speech_recognizer.canceled.connect(canceled)

    speech_recognizer.start_continuous_recognition()

    while not stop_signal.is_set():    # ‡∏ü‡∏±‡∏á‡πÄ‡∏£‡∏∑‡πà‡∏≠‡∏¢ ‡πÜ ‡∏à‡∏ô‡∏Å‡∏ß‡πà‡∏≤‡∏à‡∏∞‡∏°‡∏µ stop_signal
        time.sleep(0.1)

    speech_recognizer.stop_continuous_recognition()


# ---------- TTS ----------
# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏û‡∏π‡∏î‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏ß‡πà‡∏≤‡∏°‡∏µ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏û‡∏π‡∏î‡πÅ‡∏ó‡∏£‡∏Å‡∏´‡∏£‡∏∑‡∏≠‡πÑ‡∏°‡πà
def tts_with_cancel_on_speech(text):
    global intent_result

    if not AZURE_SPEECH_KEY or not AZURE_REGION:
        print("‚ùå ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÉ‡∏™‡πà‡∏Ñ‡∏µ‡∏¢‡πå‡πÉ‡∏ô .env")
        return

    # ‡πÄ‡∏Ñ‡∏•‡∏µ‡∏¢‡∏£‡πå signal ‡∏Å‡πà‡∏≠‡∏ô‡πÄ‡∏£‡∏¥‡πà‡∏°
    cancel_signal.clear()
    start_vad_signal.clear()
    intent_result = None

    speech_config = speechsdk.SpeechConfig(subscription=AZURE_SPEECH_KEY, region=AZURE_REGION)
    speech_config.set_speech_synthesis_output_format(
        speechsdk.SpeechSynthesisOutputFormat.Raw16Khz16BitMonoPcm
    )

    synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=None)
    result = synthesizer.speak_text_async(text).get()  # ‡πÅ‡∏õ‡∏•‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á

    if result.reason != speechsdk.ResultReason.SynthesizingAudioCompleted:
        speech_config.speech_synthesis_voice_name = "th-TH-NiwatNeural"
        print("‚ùå ‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î:", speechsdk.CancellationDetails.from_result(result).error_details)
        return

    audio_data = result.audio_data
    audio_np = np.frombuffer(audio_data, dtype=np.int16)  # ‡πÅ‡∏õ‡∏•‡∏á‡πÄ‡∏õ‡πá‡∏ô numpy array

    audio_duration = len(audio_np) / SAMPLE_RATE
    print(f"üïí ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡πÄ‡∏™‡∏µ‡∏¢‡∏á {audio_duration:.2f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ")

    chunk_size = int(SAMPLE_RATE * 0.3)  # ‡πÅ‡∏ö‡πà‡∏á‡πÄ‡∏•‡πà‡∏ô‡∏ó‡∏µ‡∏•‡∏∞ 0.3 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ

    print("‚ñ∂Ô∏è ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏û‡∏π‡∏î...")

    # ‡πÄ‡∏£‡∏¥‡πà‡∏° Thread ‡∏ü‡∏±‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á
    stop_signal.clear()
    cancel_signal.clear()
    start_vad_signal.set()
    intent_result = None

    mic_thread = threading.Thread(target=detect_human_voice_by_stt_continuous)
    mic_thread.start()

    start_time = time.time()

    with sd.OutputStream(samplerate=SAMPLE_RATE, channels=1, dtype='int16') as stream:
        i = 0
        while i < len(audio_np):
            if cancel_signal.is_set():  # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏û‡∏π‡∏î‡πÅ‡∏ó‡∏£‡∏Å ‚Üí ‡∏´‡∏¢‡∏∏‡∏î‡∏û‡∏π‡∏î
                print("üõë ‡∏´‡∏¢‡∏∏‡∏î‡∏û‡∏π‡∏î‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏°‡∏µ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏û‡∏π‡∏î‡πÅ‡∏ó‡∏£‡∏Å")
                break

            end = min(i + chunk_size, len(audio_np))
            stream.write(audio_np[i:end])  # ‡πÄ‡∏•‡πà‡∏ô‡πÄ‡∏™‡∏µ‡∏¢‡∏á
            i = end

    elapsed_time = time.time() - start_time
    print(f"üïí ‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡∏û‡∏π‡∏î‡∏à‡∏£‡∏¥‡∏á {elapsed_time:.2f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ")

    start_vad_signal.clear()  # ‡∏õ‡∏¥‡∏î VAD
    stop_signal.set()         # ‡∏™‡∏±‡πà‡∏á‡∏´‡∏¢‡∏∏‡∏î‡∏ü‡∏±‡∏á
    mic_thread.join()         # ‡∏£‡∏≠ Thread ‡∏ü‡∏±‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏à‡∏ö

    # ‡∏ñ‡πâ‡∏≤‡∏°‡∏µ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÅ‡∏ó‡∏£‡∏Å
    if cancel_signal.is_set():
        if intent_result == "interrupt":
            print("üëâ ‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏Ñ‡πà‡∏Å‡∏≤‡∏£‡πÅ‡∏ó‡∏£‡∏Å ‚Üí ‡∏û‡∏π‡∏î‡∏ï‡πà‡∏≠‡∏à‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏´‡∏¢‡∏∏‡∏î")
            remaining_audio = audio_np[i:]
            if len(remaining_audio) > 0:
                tts_with_cancel_on_speech_from_audio(remaining_audio)  # ‡∏û‡∏π‡∏î‡∏ï‡πà‡∏≠
            else:
                print("‚úÖ ‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏Ñ‡πâ‡∏≤‡∏á ‚Üí ‡∏à‡∏ö‡πÅ‡∏•‡πâ‡∏ß")

        elif intent_result == "question":
            print("üëâ ‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° ‚Üí ‡∏´‡∏¢‡∏∏‡∏î‡πÄ‡∏•‡πà‡∏≤‡πÅ‡∏•‡πâ‡∏ß‡πÑ‡∏õ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°")
            print("ü§ñ [AI] ‚Üí ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ")

    else:
        print("‚úÖ ‡∏û‡∏π‡∏î‡∏à‡∏ô‡∏à‡∏ö")


# üî• ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏û‡∏π‡∏î‡∏ï‡πà‡∏≠‡∏à‡∏≤‡∏Å‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏ó‡∏µ‡πà‡πÄ‡∏´‡∏•‡∏∑‡∏≠
def tts_with_cancel_on_speech_from_audio(audio_np):
    chunk_size = int(SAMPLE_RATE * 0.3)

    stop_signal.clear()
    cancel_signal.clear()
    start_vad_signal.set()
    global intent_result
    intent_result = None

    mic_thread = threading.Thread(target=detect_human_voice_by_stt_continuous)
    mic_thread.start()

    start_time = time.time()

    with sd.OutputStream(samplerate=SAMPLE_RATE, channels=1, dtype='int16') as stream:
        i = 0
        while i < len(audio_np):
            if cancel_signal.is_set():
                print("üõë ‡∏´‡∏¢‡∏∏‡∏î‡∏û‡∏π‡∏î‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏°‡∏µ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏û‡∏π‡∏î‡πÅ‡∏ó‡∏£‡∏Å")
                break

            end = min(i + chunk_size, len(audio_np))
            stream.write(audio_np[i:end])
            i = end

    elapsed_time = time.time() - start_time
    print(f"üïí ‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡∏û‡∏π‡∏î‡∏ï‡πà‡∏≠ {elapsed_time:.2f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ")

    start_vad_signal.clear()
    stop_signal.set()
    mic_thread.join()

    if cancel_signal.is_set():
        if intent_result == "interrupt":
            print("üëâ ‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏Ñ‡πà‡∏Å‡∏≤‡∏£‡πÅ‡∏ó‡∏£‡∏Å ‚Üí ‡∏û‡∏π‡∏î‡∏ï‡πà‡∏≠‡∏à‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏´‡∏¢‡∏∏‡∏î")
            remaining_audio = audio_np[i:]
            if len(remaining_audio) > 0:
                tts_with_cancel_on_speech_from_audio(remaining_audio)
            else:
                print("‚úÖ ‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏Ñ‡πâ‡∏≤‡∏á ‚Üí ‡∏à‡∏ö‡πÅ‡∏•‡πâ‡∏ß")

        elif intent_result == "question":
            print("üëâ ‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° ‚Üí ‡∏´‡∏¢‡∏∏‡∏î‡πÄ‡∏•‡πà‡∏≤‡πÅ‡∏•‡πâ‡∏ß‡πÑ‡∏õ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°")
            print("ü§ñ [AI] ‚Üí ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ")
    else:
        print("‚úÖ ‡∏û‡∏π‡∏î‡∏à‡∏ô‡∏à‡∏ö")


# ---------- Main ----------
if __name__ == "__main__":
    # ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡∏ï‡∏±‡∏ß‡∏≠‡∏¢‡πà‡∏≤‡∏á‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ó‡∏î‡∏™‡∏≠‡∏ö
    text = "‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡∏£‡∏∞‡∏ö‡∏ö‡∏û‡∏π‡∏î‡∏î‡πâ‡∏ß‡∏¢‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏à‡∏≤‡∏Å Azure ‡∏´‡∏≤‡∏Å‡∏°‡∏µ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏û‡∏π‡∏î‡πÅ‡∏ó‡∏£‡∏Å ‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∞‡∏´‡∏¢‡∏∏‡∏î‡∏û‡∏π‡∏î‡∏ó‡∏±‡∏ô‡∏ó‡∏µ ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° ‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∞‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° ‡πÅ‡∏ï‡πà‡∏ñ‡πâ‡∏≤‡πÅ‡∏Ñ‡πà‡∏û‡∏π‡∏î‡πÅ‡∏ó‡∏£‡∏Å ‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∞‡∏û‡∏π‡∏î‡∏ï‡πà‡∏≠‡∏à‡∏≤‡∏Å‡πÄ‡∏î‡∏¥‡∏°"

    stop_signal.clear()
    cancel_signal.clear()

    try:
        tts_with_cancel_on_speech(text)  # ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏û‡∏π‡∏î‡∏´‡∏•‡∏±‡∏Å
    finally:
        stop_signal.set()
        print("üõë ‡∏à‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô")
