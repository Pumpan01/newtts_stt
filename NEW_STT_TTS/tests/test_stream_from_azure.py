# ‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤ Library ‡∏ó‡∏µ‡πà‡πÉ‡∏ä‡πâ
import azure.cognitiveservices.speech as speechsdk
import sounddevice as sd
import numpy as np
import threading
import time
import os
from dotenv import load_dotenv
from pathlib import Path
import random


# ---------- Load API KEY ----------
env_path = Path(__file__).resolve().parent / ".env"
load_dotenv(dotenv_path=env_path)

AZURE_SPEECH_KEY = os.getenv("AZURE_SPEECH_KEY")
AZURE_REGION = os.getenv("AZURE_SPEECH_REGION")


# ---------- Config ----------
SAMPLE_RATE = 16000
FRAME_DURATION = 30
FRAME_SIZE = int(SAMPLE_RATE * FRAME_DURATION / 1000)


# ---------- Signal ----------
stop_signal = threading.Event()
cancel_signal = threading.Event()
start_vad_signal = threading.Event()
intent_result = None


# ---------- ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏™‡∏∏‡πà‡∏° Emotion ‡πÅ‡∏•‡∏∞ Gesture ‡∏ï‡∏≠‡∏ô‡πÇ‡∏î‡∏ô‡∏Ç‡∏±‡∏î ----------
def get_interrupt_emotion():
    emotions = ["angry", "neutral", "surprised", "sad"]
    return random.choice(emotions)


def get_interrupt_gesture():
    gestures = ["shake_head", "neutral_face", "surprise_face", "sad_face"]
    return random.choice(gestures)


# ---------- Intent Check ----------
def check_intent(text):
    question_keywords = ["‡∏≠‡∏∞‡πÑ‡∏£", "‡∏ó‡∏≥‡πÑ‡∏°", "‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÑ‡∏´‡∏£‡πà", "‡∏¢‡∏±‡∏á‡πÑ‡∏á", "‡∏ó‡∏µ‡πà‡πÑ‡∏´‡∏ô", "‡πÉ‡∏Ñ‡∏£", "‡πÉ‡∏ä‡πà‡πÑ‡∏´‡∏°", "‡∏´‡∏£‡∏∑‡∏≠‡πÄ‡∏õ‡∏•‡πà‡∏≤", "‡∏Å‡∏µ‡πà", "‡πÑ‡∏´‡∏°"]
    for word in question_keywords:
        if word in text:
            return "question"
    return "interrupt"


# ---------- STT Detect ----------
def detect_human_voice_by_stt_continuous():
    global intent_result

    speech_config = speechsdk.SpeechConfig(subscription=AZURE_SPEECH_KEY, region=AZURE_REGION)
    speech_config.speech_recognition_language = "th-TH"
    audio_config = speechsdk.audio.AudioConfig(use_default_microphone=True)

    recognizer = speechsdk.SpeechRecognizer(
        speech_config=speech_config, audio_config=audio_config
    )

    def recognized(evt):
        global intent_result
        if start_vad_signal.is_set():
            text = evt.result.text.strip()
            if text:
                print(f"üõë ‡∏ï‡∏£‡∏ß‡∏à‡∏û‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏û‡∏π‡∏î: {text}")
                intent_result = check_intent(text)
                cancel_signal.set()

    def canceled(evt):
        print(f"‚ùå STT ‡∏¢‡∏Å‡πÄ‡∏•‡∏¥‡∏Å: {evt}")

    recognizer.recognized.connect(recognized)
    recognizer.canceled.connect(canceled)

    recognizer.start_continuous_recognition()

    while not stop_signal.is_set():
        time.sleep(0.2)

    recognizer.stop_continuous_recognition()


# ---------- TTS ----------
# ---------- TTS ----------

def tts_with_cancel_on_speech(text):
    global intent_result

    if not AZURE_SPEECH_KEY or not AZURE_REGION:
        print("‚ùå ‡∏Å‡∏£‡∏∏‡∏ì‡∏≤‡πÉ‡∏™‡πà‡∏Ñ‡∏µ‡∏¢‡πå‡πÉ‡∏ô .env")
        return

    cancel_signal.clear()
    start_vad_signal.clear()
    intent_result = None

    speech_config = speechsdk.SpeechConfig(subscription=AZURE_SPEECH_KEY, region=AZURE_REGION)
    speech_config.set_speech_synthesis_output_format(
        speechsdk.SpeechSynthesisOutputFormat.Raw16Khz16BitMonoPcm
    )

    synthesizer = speechsdk.SpeechSynthesizer(speech_config=speech_config, audio_config=None)
    result = synthesizer.speak_text_async(text).get()

    if result.reason != speechsdk.ResultReason.SynthesizingAudioCompleted:
        print("‚ùå ‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î:", speechsdk.CancellationDetails.from_result(result).error_details)
        return

    audio_data = result.audio_data
    audio_np = np.frombuffer(audio_data, dtype=np.int16)

    audio_duration = len(audio_np) / SAMPLE_RATE
    print(f"üïí ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏¢‡∏≤‡∏ß‡πÄ‡∏™‡∏µ‡∏¢‡∏á {audio_duration:.2f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ")

    chunk_size = int(SAMPLE_RATE * 0.3)

    print("‚ñ∂Ô∏è ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏û‡∏π‡∏î...")

    stop_signal.clear()
    cancel_signal.clear()
    start_vad_signal.set()
    intent_result = None

    mic_thread = threading.Thread(target=detect_human_voice_by_stt_continuous)
    mic_thread.start()

    start_time = time.time()

    with sd.OutputStream(samplerate=SAMPLE_RATE, channels=1, dtype='int16') as stream:
        i = 0
        while i < len(audio_np):
            if cancel_signal.is_set():
                interrupt_emotion = get_interrupt_emotion()
                interrupt_gesture = get_interrupt_gesture()

                print("üõë ‡∏´‡∏¢‡∏∏‡∏î‡∏û‡∏π‡∏î‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏°‡∏µ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏û‡∏π‡∏î‡πÅ‡∏ó‡∏£‡∏Å")
                print(f"ü§ñ [Emotion: {interrupt_emotion}] [Gesture: {interrupt_gesture}] ‚Üí ‡πÅ‡∏™‡∏î‡∏á‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏ï‡∏≠‡∏ô‡πÇ‡∏î‡∏ô‡∏Ç‡∏±‡∏î")

                if intent_result == "question":
                    print("üëâ ‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° ‚Üí ‡∏´‡∏¢‡∏∏‡∏î‡πÄ‡∏•‡πà‡∏≤‡πÅ‡∏•‡πâ‡∏ß‡πÑ‡∏õ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°")
                    print("ü§ñ [AI] ‚Üí ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ")
                    stop_signal.set()
                    start_vad_signal.clear()
                    mic_thread.join()
                    return  # ‚õî ‡∏´‡∏¢‡∏∏‡∏î‡∏û‡∏π‡∏î‡∏ó‡∏±‡∏ô‡∏ó‡∏µ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÑ‡∏õ‡∏ï‡∏≠‡∏ö

                elif intent_result == "interrupt":
                    print("üëâ ‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏Ñ‡πà‡∏Å‡∏≤‡∏£‡πÅ‡∏ó‡∏£‡∏Å ‚Üí ‡∏´‡∏¢‡∏∏‡∏î 2 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡πÅ‡∏•‡πâ‡∏ß‡∏û‡∏π‡∏î‡∏ï‡πà‡∏≠")
                    time.sleep(4)  # üõë ‡∏´‡∏¢‡∏∏‡∏î 2 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ
                    cancel_signal.clear()  # üü© ‡πÄ‡∏Ñ‡∏•‡∏µ‡∏¢‡∏£‡πå signal ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡∏û‡∏π‡∏î‡∏ï‡πà‡∏≠

            end = min(i + chunk_size, len(audio_np))
            stream.write(audio_np[i:end])
            i = end

    elapsed_time = time.time() - start_time
    print(f"üïí ‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡∏û‡∏π‡∏î‡∏à‡∏£‡∏¥‡∏á {elapsed_time:.2f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ")

    start_vad_signal.clear()
    stop_signal.set()
    mic_thread.join()

    print("‚úÖ ‡∏û‡∏π‡∏î‡∏à‡∏ô‡∏à‡∏ö")


# ---------- ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏û‡∏π‡∏î‡∏ï‡πà‡∏≠ ----------
def tts_with_cancel_on_speech_from_audio(audio_np):
    chunk_size = int(SAMPLE_RATE * 0.3)

    stop_signal.clear()
    cancel_signal.clear()
    start_vad_signal.set()
    global intent_result
    intent_result = None

    mic_thread = threading.Thread(target=detect_human_voice_by_stt_continuous)
    mic_thread.start()

    start_time = time.time()

    with sd.OutputStream(samplerate=SAMPLE_RATE, channels=1, dtype='int16') as stream:
        i = 0
        while i < len(audio_np):
            if cancel_signal.is_set():
                interrupt_emotion = get_interrupt_emotion()
                interrupt_gesture = get_interrupt_gesture()

                print("üõë ‡∏´‡∏¢‡∏∏‡∏î‡∏û‡∏π‡∏î‡πÄ‡∏û‡∏£‡∏≤‡∏∞‡∏°‡∏µ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏û‡∏π‡∏î‡πÅ‡∏ó‡∏£‡∏Å")
                print(f"ü§ñ [Emotion: {interrupt_emotion}] [Gesture: {interrupt_gesture}] ‚Üí ‡πÅ‡∏™‡∏î‡∏á‡∏≠‡∏≤‡∏£‡∏°‡∏ì‡πå‡∏ï‡∏≠‡∏ô‡πÇ‡∏î‡∏ô‡∏Ç‡∏±‡∏î")
                time.sleep(2)  # ‚úÖ ‡∏´‡∏¢‡∏∏‡∏î 2 ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ‡∏´‡∏•‡∏±‡∏á‡∏ñ‡∏π‡∏Å‡∏Ç‡∏±‡∏î
                break

            end = min(i + chunk_size, len(audio_np))
            stream.write(audio_np[i:end])
            i = end

    elapsed_time = time.time() - start_time
    print(f"üïí ‡πÉ‡∏ä‡πâ‡πÄ‡∏ß‡∏•‡∏≤‡∏û‡∏π‡∏î‡∏ï‡πà‡∏≠ {elapsed_time:.2f} ‡∏ß‡∏¥‡∏ô‡∏≤‡∏ó‡∏µ")

    start_vad_signal.clear()
    stop_signal.set()
    mic_thread.join()

    if cancel_signal.is_set():
        if intent_result == "interrupt":
            print("üëâ ‡πÄ‡∏õ‡πá‡∏ô‡πÅ‡∏Ñ‡πà‡∏Å‡∏≤‡∏£‡πÅ‡∏ó‡∏£‡∏Å ‚Üí ‡∏û‡∏π‡∏î‡∏ï‡πà‡∏≠‡∏à‡∏≤‡∏Å‡∏ó‡∏µ‡πà‡∏´‡∏¢‡∏∏‡∏î")
            remaining_audio = audio_np[i:]
            if len(remaining_audio) > 0:
                tts_with_cancel_on_speech_from_audio(remaining_audio)
            else:
                print("‚úÖ ‡πÑ‡∏°‡πà‡∏°‡∏µ‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏Ñ‡πâ‡∏≤‡∏á ‚Üí ‡∏à‡∏ö‡πÅ‡∏•‡πâ‡∏ß")
        elif intent_result == "question":
            print("üëâ ‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° ‚Üí ‡∏´‡∏¢‡∏∏‡∏î‡πÄ‡∏•‡πà‡∏≤‡πÅ‡∏•‡πâ‡∏ß‡πÑ‡∏õ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°")
            print("ü§ñ [AI] ‚Üí ‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏°‡∏ï‡∏£‡∏á‡∏ô‡∏µ‡πâ")
    else:
        print("‚úÖ ‡∏û‡∏π‡∏î‡∏à‡∏ô‡∏à‡∏ö")


# ---------- Main ----------
if __name__ == "__main__":
    text = "‡∏ô‡∏µ‡πà‡∏Ñ‡∏∑‡∏≠‡∏£‡∏∞‡∏ö‡∏ö‡∏û‡∏π‡∏î‡∏î‡πâ‡∏ß‡∏¢‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏à‡∏≤‡∏Å Azure ‡∏´‡∏≤‡∏Å‡∏°‡∏µ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏û‡∏π‡∏î‡πÅ‡∏ó‡∏£‡∏Å ‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∞‡∏´‡∏¢‡∏∏‡∏î‡∏û‡∏π‡∏î‡∏ó‡∏±‡∏ô‡∏ó‡∏µ ‡∏ñ‡πâ‡∏≤‡πÄ‡∏õ‡πá‡∏ô‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° ‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∞‡∏ï‡∏≠‡∏ö‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° ‡πÅ‡∏ï‡πà‡∏ñ‡πâ‡∏≤‡πÅ‡∏Ñ‡πà‡∏û‡∏π‡∏î‡πÅ‡∏ó‡∏£‡∏Å ‡∏£‡∏∞‡∏ö‡∏ö‡∏à‡∏∞‡∏û‡∏π‡∏î‡∏ï‡πà‡∏≠‡∏à‡∏≤‡∏Å‡πÄ‡∏î‡∏¥‡∏°"

    stop_signal.clear()
    cancel_signal.clear()

    try:
        tts_with_cancel_on_speech(text)
    finally:
        stop_signal.set()
        print("üõë ‡∏à‡∏ö‡∏Å‡∏≤‡∏£‡∏ó‡∏≥‡∏á‡∏≤‡∏ô")
