# ‡∏ô‡∏≥‡πÄ‡∏Ç‡πâ‡∏≤‡πÑ‡∏•‡∏ö‡∏£‡∏≤‡∏£‡∏µ‡∏ó‡∏µ‡πà‡∏à‡∏≥‡πÄ‡∏õ‡πá‡∏ô
import cv2                        # OpenCV ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏õ‡∏£‡∏∞‡∏°‡∏ß‡∏•‡∏ú‡∏•‡∏†‡∏≤‡∏û
import mediapipe as mp             # MediaPipe ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏Ñ‡∏ô‡πÉ‡∏ô‡∏Å‡∏•‡πâ‡∏≠‡∏á
import azure.cognitiveservices.speech as speechsdk  # Azure Speech SDK ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö STT
import sounddevice as sd           # ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏à‡∏≤‡∏Å‡πÑ‡∏°‡∏Ñ‡πå
import numpy as np                 # ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÅ‡∏ö‡∏ö array
import webrtcvad                   # ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏û‡∏π‡∏î/‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏á‡∏µ‡∏¢‡∏ö (VAD)
import requests                    # ‡∏™‡πà‡∏á request ‡πÑ‡∏õ API
import threading                   # ‡∏£‡∏±‡∏ô‡∏´‡∏•‡∏≤‡∏¢ thread ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô
import time                        # ‡∏à‡∏±‡∏ö‡πÄ‡∏ß‡∏•‡∏≤
import os                          # ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£‡πÑ‡∏ü‡∏•‡πå
from dotenv import load_dotenv     # ‡πÇ‡∏´‡∏•‡∏î‡∏ï‡∏±‡∏ß‡πÅ‡∏õ‡∏£‡∏à‡∏≤‡∏Å .env
from pathlib import Path           # ‡∏à‡∏±‡∏î‡∏Å‡∏≤‡∏£ path
import keyboard                    # ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏Å‡∏≤‡∏£‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏°‡∏ö‡∏ô‡∏Ñ‡∏µ‡∏¢‡πå‡∏ö‡∏≠‡∏£‡πå‡∏î


# ---------- ‡πÇ‡∏´‡∏•‡∏î API KEY ‡∏à‡∏≤‡∏Å‡πÑ‡∏ü‡∏•‡πå .env ----------
env_path = Path(__file__).resolve().parent / "tests" / ".env"
load_dotenv(dotenv_path=env_path)

AZURE_SPEECH_KEY = os.getenv("AZURE_SPEECH_KEY")    # ‡∏Ñ‡∏µ‡∏¢‡πå‡∏Ç‡∏≠‡∏á Azure Speech
AZURE_REGION = os.getenv("AZURE_SPEECH_REGION")     # Region ‡∏Ç‡∏≠‡∏á Azure Speech
API_ASKDAMO = "http://localhost:3000/0921_chatbot_demo/api/askDamo"  # API ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö chatbot


# ---------- ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Log ----------
LOG_FILE = "log.txt"

def write_log(message):
    print(message)
    with open(LOG_FILE, "a", encoding="utf-8") as f:
        f.write(f"[{time.ctime()}] {message}\n")


# ---------- ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ MediaPipe ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏Ñ‡∏ô ----------
mp_selfie_segmentation = mp.solutions.selfie_segmentation
selfie_segmentation = mp_selfie_segmentation.SelfieSegmentation(model_selection=1)


# ---------- ‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏á‡∏µ‡∏¢‡∏ö‡∏î‡πâ‡∏ß‡∏¢ webrtcvad ----------
def wait_for_silence(vad_aggressiveness=2, silence_duration=3, sample_rate=16000):
    vad = webrtcvad.Vad(vad_aggressiveness)     # ‡∏™‡∏£‡πâ‡∏≤‡∏á‡∏ï‡∏±‡∏ß‡∏ï‡∏£‡∏ß‡∏à‡∏à‡∏±‡∏ö‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏û‡∏π‡∏î
    silence_start = None
    block_duration = 0.03  # 30ms

    def is_speech(audio_chunk):
        audio_bytes = (audio_chunk * 32768).astype(np.int16).tobytes()
        return vad.is_speech(audio_bytes, sample_rate)

    try:
        with sd.InputStream(samplerate=sample_rate, channels=1, dtype='float32') as stream:
            while True:
                audio_chunk, _ = stream.read(int(sample_rate * block_duration))
                if is_speech(audio_chunk):
                    silence_start = None  # ‡∏°‡∏µ‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡∏û‡∏π‡∏î ‚Üí ‡∏£‡∏µ‡πÄ‡∏ã‡πá‡∏ï‡∏ï‡∏±‡∏ß‡∏à‡∏±‡∏ö‡πÄ‡∏ß‡∏•‡∏≤
                else:
                    if silence_start is None:
                        silence_start = time.time()  # ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏à‡∏±‡∏ö‡πÄ‡∏ß‡∏•‡∏≤‡πÄ‡∏°‡∏∑‡πà‡∏≠‡πÄ‡∏à‡∏≠‡πÄ‡∏™‡∏µ‡∏¢‡∏á‡πÄ‡∏á‡∏µ‡∏¢‡∏ö
                    elif time.time() - silence_start >= silence_duration:
                        break  # ‡∏ñ‡πâ‡∏≤‡πÄ‡∏á‡∏µ‡∏¢‡∏ö‡∏ï‡πà‡∏≠‡πÄ‡∏ô‡∏∑‡πà‡∏≠‡∏á‡πÄ‡∏Å‡∏¥‡∏ô silence_duration ‚Üí ‡∏´‡∏¢‡∏∏‡∏î
    except Exception as e:
        write_log(f"‚ùå Error in VAD: {e}")


# ---------- ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡πÄ‡∏õ‡∏¥‡∏î‡πÑ‡∏°‡∏Ñ‡πå‡∏ü‡∏±‡∏á‡∏à‡∏ô‡πÄ‡∏á‡∏µ‡∏¢‡∏ö‡πÅ‡∏•‡πâ‡∏ß‡∏™‡πà‡∏á‡πÑ‡∏õ API ----------
def listen_and_send(stop_event):
    speech_config = speechsdk.SpeechConfig(subscription=AZURE_SPEECH_KEY, region=AZURE_REGION)
    speech_config.speech_recognition_language = "th-TH"
    audio_config = speechsdk.audio.AudioConfig(use_default_microphone=True)

    recognizer = speechsdk.SpeechRecognizer(speech_config=speech_config, audio_config=audio_config)

    while not stop_event.is_set():   # ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏à‡∏ô‡∏Å‡∏ß‡πà‡∏≤‡∏à‡∏∞‡∏°‡∏µ‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏´‡∏¢‡∏∏‡∏î
        full_text = []

        def recognized(evt):
            if evt.result.reason == speechsdk.ResultReason.RecognizedSpeech:
                write_log(f"üìù ‡πÑ‡∏î‡πâ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°: {evt.result.text}")
                full_text.append(evt.result.text)

        recognizer.recognized.connect(recognized)

        write_log("üéôÔ∏è ‡πÄ‡∏õ‡∏¥‡∏î‡πÑ‡∏°‡∏Ñ‡πå (‡∏û‡∏π‡∏î‡∏à‡∏ô‡πÄ‡∏á‡∏µ‡∏¢‡∏ö 2 ‡∏ß‡∏¥)")
        recognizer.start_continuous_recognition()

        wait_for_silence(silence_duration=2)  # ‡∏ü‡∏±‡∏á‡∏à‡∏ô‡πÄ‡∏á‡∏µ‡∏¢‡∏ö 2 ‡∏ß‡∏¥

        recognizer.stop_continuous_recognition()
        recognizer.recognized.disconnect_all()

        text = ' '.join(full_text).strip()

        if text:
            write_log(f"üì® ‡∏™‡πà‡∏á‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°‡πÑ‡∏õ API: {text}")
            try:
                response = requests.post(API_ASKDAMO, json={"question": text})
                response.raise_for_status()
                write_log("‚úÖ ‡∏™‡πà‡∏á‡∏™‡∏≥‡πÄ‡∏£‡πá‡∏à ‡∏£‡∏≠‡∏£‡∏≠‡∏ö‡πÉ‡∏´‡∏°‡πà...")
            except Exception as e:
                write_log(f"‚ùå ‡∏™‡πà‡∏á API ‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}")
        else:
            write_log("‚ö†Ô∏è ‡πÑ‡∏°‡πà‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏Ñ‡∏ß‡∏≤‡∏°")

        time.sleep(0.1)


# ---------- ‡πÄ‡∏£‡∏¥‡πà‡∏°‡πÄ‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á ----------
cap = cv2.VideoCapture(1)  # ‡πÉ‡∏ä‡πâ‡∏Å‡∏•‡πâ‡∏≠‡∏á‡∏ï‡∏±‡∏ß‡∏ó‡∏µ‡πà 1 (‡∏´‡∏£‡∏∑‡∏≠ 0 ‡πÅ‡∏•‡πâ‡∏ß‡πÅ‡∏ï‡πà‡πÄ‡∏Ñ‡∏£‡∏∑‡πà‡∏≠‡∏á)

mic_on = False                     # ‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏ß‡πà‡∏≤‡πÑ‡∏°‡∏Ñ‡πå‡πÄ‡∏õ‡∏¥‡∏î‡πÑ‡∏´‡∏°
mic_thread = None                  # Thread ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡πÑ‡∏°‡∏Ñ‡πå
stop_event = threading.Event()     # Signal ‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏´‡∏¢‡∏∏‡∏î‡πÑ‡∏°‡∏Ñ‡πå

write_log("üéâ ‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡∏ï‡πâ‡∏≠‡∏ô‡∏£‡∏±‡∏ö! ‡∏û‡∏£‡πâ‡∏≠‡∏°‡πÅ‡∏•‡πâ‡∏ß ‡∏û‡∏π‡∏î‡∏≠‡∏∞‡πÑ‡∏£‡∏Å‡∏±‡∏ö‡∏â‡∏±‡∏ô‡∏Å‡πá‡πÑ‡∏î‡πâ‡πÄ‡∏•‡∏¢ üòé")

while cap.isOpened():              # ‡∏ó‡∏≥‡∏á‡∏≤‡∏ô‡∏à‡∏ô‡∏Å‡∏ß‡πà‡∏≤‡∏à‡∏∞‡∏õ‡∏¥‡∏î‡∏Å‡∏•‡πâ‡∏≠‡∏á
    success, frame = cap.read()
    if not success:
        break

    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
    results = selfie_segmentation.process(frame_rgb)

    condition = results.segmentation_mask > 0.5   # ‡πÄ‡∏ä‡πá‡∏Ñ‡∏ß‡πà‡∏≤‡∏°‡∏µ‡∏Ñ‡∏ô‡πÉ‡∏ô‡∏Å‡∏•‡πâ‡∏≠‡∏á‡πÑ‡∏´‡∏°
    has_person = condition.any()

    if has_person:
        if not mic_on:
            write_log("üëÄ ‡∏û‡∏ö‡∏Ñ‡∏ô ‚Üí ‡πÄ‡∏õ‡∏¥‡∏î‡πÑ‡∏°‡∏Ñ‡πå")
            stop_event.clear()   # ‡∏¢‡∏Å‡πÄ‡∏•‡∏¥‡∏Å‡∏Ñ‡∏≥‡∏™‡∏±‡πà‡∏á‡∏´‡∏¢‡∏∏‡∏î
            mic_thread = threading.Thread(target=listen_and_send, args=(stop_event,))
            mic_thread.start()   # ‡πÄ‡∏£‡∏¥‡πà‡∏° thread ‡∏ü‡∏±‡∏á‡πÄ‡∏™‡∏µ‡∏¢‡∏á
            mic_on = True
    else:
        if mic_on:
            write_log("‚ùå ‡πÑ‡∏°‡πà‡∏û‡∏ö‡∏Ñ‡∏ô ‚Üí ‡∏£‡∏≠‡πÉ‡∏´‡πâ‡∏û‡∏π‡∏î‡∏à‡∏ö‡∏Å‡πà‡∏≠‡∏ô ‡πÅ‡∏•‡πâ‡∏ß‡∏õ‡∏¥‡∏î‡πÑ‡∏°‡∏Ñ‡πå")
            stop_event.set()     # ‡∏™‡∏±‡πà‡∏á‡πÉ‡∏´‡πâ‡∏´‡∏¢‡∏∏‡∏î‡∏ü‡∏±‡∏á
            mic_thread.join()    # ‡∏£‡∏≠‡πÉ‡∏´‡πâ thread ‡∏à‡∏ö‡∏Å‡πà‡∏≠‡∏ô
            mic_on = False

    # ‡∏ñ‡πâ‡∏≤‡∏Å‡∏î‡∏õ‡∏∏‡πà‡∏° ESC ‚Üí ‡∏´‡∏¢‡∏∏‡∏î‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°
    if keyboard.is_pressed('esc'):
        write_log("üëã ‡∏≠‡∏≠‡∏Å‡∏à‡∏≤‡∏Å‡πÇ‡∏õ‡∏£‡πÅ‡∏Å‡∏£‡∏°")
        if mic_on:
            stop_event.set()
            mic_thread.join()
        break

cap.release()
cv2.destroyAllWindows()
